Spark
	JavaRDD [TRANSFORMATIONS]
		filter: 	boolean filter for each row (yes or no), like grep
		map:		function apply for each row, which returns a custom part of row
		flatmap:	function apply for each row, which returns an array of custom parts of row
					the array will be used to expand data in a vertical fashion
					1 -> N (es.: 1 ROW -> MANY ROWS) 
		distinct:	show only 1 different row
	
	JavaRDD [ACTIONS]
		top(n):		the n biggest value
		collect():	all values
		count:		count all values
		countByValue: returns Map with <key,n occurrences>
		reduce:		Execute Function2(3 types) to all records and returns 1 value
	
	2 JavaRDD[TRANSFORMATIONS]
		Union:			union 2 RDD in 1 RDD
		InterSection:	Return common keys
			
		
	JavaRDDPair
		reduceByKey: Apply 1 function to all values, one pair, result, one pair
		combineByKey: Apply 3 functions: 1. Start, 2. 1 Value with Previous, 3. Each Other from 2 Partitions
		GroupByKey:  Group all Values in 1 Iterable Array  
	
	2 JavaRDDPair
		coGroup:	 Group all Values in 2 Iterable Array     
		join:		 join with same key
		
		
public class UserWatchedGenre implements PairFunction<Tuple2<String, Tuple2<String, String>>, String, String> {

        @Override
        public Tuple2<String, String> call(Tuple2<String, Tuple2<String, String>> userMovie) {

                // movieid - userid - genre
                Tuple2<String, String> movieGenre=
                                new Tuple2<String, String>(userMovie._2()._1(), userMovie._2()._2());

                return movieGenre;
        }

}		